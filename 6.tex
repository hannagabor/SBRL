\documentclass[12pt,a4paper]{article}
\usepackage[left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{amssymb, amsmath, amsthm}
\usepackage{graphics, graphicx}
\pagestyle{empty}


\begin{document}
\textbf{Chapter 6 solutions  \hfill Hanna GÃ¡bor}\\

\begin{enumerate}

\item
\begin{align*}
G_t - V_t(S_t) & = R_{t + 1} + \gamma G_{t + 1} - V_t(S_t) + \gamma V_t(S_{t + 1}) -
\gamma V_t(S_{t + 1}) + \gamma V_{t + 1}(S_{t + 1}) - \gamma V_{t + 1}(S_{t + 1})\\
& = (R_{t + 1} + \gamma V_t(S_{t + 1}) - V_t(S_t)) + (\gamma G_{t + 1} - \gamma V_{t + 1}(S_{t + 1})) + (\gamma V_{t + 1}(S_{t + 1}) -\gamma V_t(S_{t + 1}))\\
& = \delta_t + \gamma(G_{t + 1} - V_{t + 1}(S_{t + 1})) + \gamma \alpha \delta_{t + 1}\\
& = \delta_t + \gamma \alpha \delta_{t + 1} + \gamma \delta_{t + 1} + \gamma^2 \alpha \delta_{t + 2} + \gamma^2(G_{t + 2} - V_{t + 2}(S_{t + 2})) = \dots\\
& = \sum\limits_{k = t}^{T - 1} \gamma^{k-t}( 1 + \alpha) \delta_{k}
\end{align*}

\item
If I get lost a few times at the beginning, then I can see why TD updates can be better.
When I get lost, only the first few states learn that it takes a long time for me to go home. After I reached the highway, the predictions won't change
just because I don't know the way from the new office building to the highway.

\item
The first episode must have terminated on the left with a reward of $-1$.

The other state values didn't change because the error in those cases was\\
$R_{t + 1} + \gamma V(S_{t + 1}) - V(S_t) = 0 + 1 \cdot 0.5 - 0.5 = 0$.

$v(A)$ changed by $\alpha (R_{t + 1} + \gamma V(S_{t + 1}) - V(S_t)) = 0.1 * (-1 + 0 - 0.5) = -0.15$.

\item
I don't think a wider range of $\alpha$ values would have an effect on the results.

\begin{itemize}
\item \textbf{Monte Carlo methods.}
The Monte Carlo version with $\alpha = 0.4$ starts to oscillate pretty fast and doesn't
seem to decrease. I expect a Monte Carlo method with a bigger $\alpha$ value to oscillate
around an error level which is at least as high as the error in the $\alpha = 0.4$
case. The smallest $\alpha$ for the MC method among the examples is $0.1$. That is
the only MC method which we can't see to oscillate. This version does not achieve the
performance of the TD methods. A smaller $\alpha$ value would make the learning progress
even slower. It's possible that the error with Monte Carlo update with $\alpha =<0.1$
goes under the TD error eventually, so looking at more episodes might have an effect
on the results.

\end{itemize}


\end{enumerate}
\end{document}
