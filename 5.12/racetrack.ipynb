{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Position = namedtuple('Position', ['row', 'col'])\n",
    "Velocity = namedtuple('Velocity', ['row', 'col'])\n",
    "Action = namedtuple('Action', ['row', 'col'])\n",
    "State = namedtuple('State', ['pos', 'vel'])\n",
    "ACTIONS = [Action(i, j) for i in [-1, 0, 1] for j in [-1, 0, 1]]\n",
    "EPSILON = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Track:\n",
    "    def __init__(self, boundaries):\n",
    "        '''Boundaries is a list of tuples. The ith tuple contains the first\n",
    "        (inclusive) and the last (exclusive) element on the track in\n",
    "        that row. The last row of the track is the start row.\n",
    "        The last column of the track is the finish line.\n",
    "        We give the boundaries from top to bottom, but store them in reversed\n",
    "        order, because the car goes upwards.'''\n",
    "        boundaries.reverse()\n",
    "        self.boundaries = boundaries\n",
    "        self.max_col = max(self.boundaries, key = lambda x: x[1])[1]\n",
    "        \n",
    "    def __str__(self, positions=None):\n",
    "        rows = []\n",
    "        for start, end in reversed(self.boundaries):\n",
    "            row = [' ' for _ in range(self.max_col)]\n",
    "            for i in range(start, end):\n",
    "                row[i] = 'O'\n",
    "            rows.append(row)\n",
    "        if positions is not None:\n",
    "            for pos in positions:\n",
    "                rows[-pos.row - 1][pos.col] = 'X'\n",
    "        str_rows = map(lambda row: ''.join(row), rows)\n",
    "        return '\\n'.join(str_rows)\n",
    "\n",
    "    def on_track(self, pos):\n",
    "        if pos.col >= self.max_col:\n",
    "            return True\n",
    "        if pos.row not in range(len(self.boundaries)):\n",
    "            return False\n",
    "        left ,right = self.boundaries[pos.row]\n",
    "        return left <= pos.col < right\n",
    "    \n",
    "    def stays_on_track(self, pos, v):\n",
    "        col = pos.col\n",
    "        row = pos.row\n",
    "        if v.row == 0:\n",
    "            col += v.col\n",
    "            return self.on_track(Position(row=row, col=col))\n",
    "        else:\n",
    "            inv_slope = v.col / v.row\n",
    "            for i in range(v.row):\n",
    "                row += 1\n",
    "                if not self.on_track(Position(row=row, col=col)):\n",
    "#                     catch intersection with a vertical border\n",
    "                    return False\n",
    "                col += inv_slope\n",
    "                if not self.on_track(Position(row=row, col=col)):\n",
    "#                     catch intersaction with a horizontal border\n",
    "                    return False\n",
    "            return True\n",
    "\n",
    "    def cross_finish(self, pos, v):\n",
    "        return pos.col + v.col >= self.max_col\n",
    "\n",
    "    def get_random_start_pos(self):\n",
    "        col = random.randrange(*self.boundaries[0])\n",
    "        return Position(row=0, col=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, track):\n",
    "        self.track = track\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.pos = self.track.get_random_start_pos()\n",
    "        self.v = Velocity(0, 0)   \n",
    "    \n",
    "    def take_action(self, a):\n",
    "        row_vel = min(5, max(0, self.v.row + a.row))\n",
    "        col_vel = min(5, max(0, self.v.col + a.col))\n",
    "        self.v = Velocity(row=row_vel, col=col_vel)\n",
    "        if self.track.stays_on_track(self.pos, self.v):\n",
    "            if self.track.cross_finish(self.pos, self.v):\n",
    "                self.pos = Position(self.pos.row + self.v.row, self.track.max_col - 1)\n",
    "                self.reset()\n",
    "#                 print(self)\n",
    "                return 0, State(pos=self.pos, vel=self.v)\n",
    "            row = self.pos.row + self.v.row\n",
    "            col = self.pos.col + self.v.col\n",
    "            self.pos = Position(row=row, col=col)\n",
    "        else:\n",
    "            self.reset()\n",
    "            return -50, State(pos=self.pos, vel=self.v)\n",
    "#         print(self)\n",
    "#         print(self.pos)\n",
    "        return -1, State(pos=self.pos, vel=self.v)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.track.__str__([self.pos])\n",
    "    \n",
    "    def get_state(self):\n",
    "        return State(pos=self.pos, vel=self.v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftPolicy:\n",
    "    def __init__(self, epsilon, track):\n",
    "        def default_probs():\n",
    "            return [1/9 for _ in range(9)]\n",
    "        self.probs = defaultdict(default_probs)\n",
    "        self.action_dict = {}\n",
    "        for i, a in enumerate(ACTIONS):\n",
    "            self.action_dict[a] = i\n",
    "        self.explore_prob = epsilon / 9\n",
    "        self.greedy_prob = 1 - epsilon + self.explore_prob\n",
    "    \n",
    "    def update(self, state, action):\n",
    "        a = self.action_dict[action]\n",
    "        for i in range(len(self.probs[state])):\n",
    "            if i == a:\n",
    "                self.probs[state][i] = self.greedy_prob\n",
    "            else:\n",
    "                self.probs[state][i] = self.explore_prob\n",
    "                \n",
    "    def get_prob(self, state, action):\n",
    "        return self.probs[state][self.action_dict[action]]\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        return ACTIONS[random.choices([i for i in range(len(ACTIONS))], weights=self.probs[state])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCPlayer:\n",
    "    def __init__(self, epsilon, env):\n",
    "        self.count = defaultdict(int)\n",
    "        self.action_value = defaultdict(int)\n",
    "        self.target_policy = {}\n",
    "        self.behavior_policy = SoftPolicy(epsilon, env.track)\n",
    "        self.env = env\n",
    "    \n",
    "    def play_episode(self):    \n",
    "        states = []\n",
    "        actions = []\n",
    "        reward = -1 # So we go into the loop.\n",
    "        state = self.env.get_state()\n",
    "        while reward == -1 :\n",
    "            states.append(state)\n",
    "            a = self.behavior_policy.get_action(state)\n",
    "            reward, state = self.env.take_action(a)\n",
    "            actions.append(a)\n",
    "        return states, actions, reward\n",
    "\n",
    "    def play_and_print(self):\n",
    "        states, actions, reward = self.play_episode()\n",
    "        print(self.env.track.__str__([state.pos for state in states]))\n",
    "        \n",
    "    \n",
    "    def learn(self, num_steps):\n",
    "        for _ in range(num_steps):\n",
    "            states, actions, G = self.play_episode()\n",
    "            imp_weight = 1\n",
    "            for i, (state, action) in enumerate(reversed(list(zip(states, actions)))):\n",
    "                if state not in states[-i]:\n",
    "#                     print('a')\n",
    "                    self.count[state] += imp_weight\n",
    "                    av = self.action_value[(state, action)]\n",
    "                    self.action_value[(state, action)] += (imp_weight\n",
    "                       / self.count[state]\n",
    "                       * (G - av))\n",
    "                    a = max(ACTIONS, key=lambda ac: self.action_value[(state, ac)])\n",
    "                    self.target_policy[state] = a\n",
    "                    self.behavior_policy.update(state, a)\n",
    "                    if a != action:\n",
    "                        break\n",
    "                    imp_weight *= 1 / self.behavior_policy.get_prob(state, a)\n",
    "                    G -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharp_turn = Track([\n",
    "#     (3, 18),\n",
    "#     (2, 18),\n",
    "#     (2, 18),\n",
    "#     (1, 18),\n",
    "#     (0, 18),\n",
    "    (0, 8),\n",
    "    (0, 7),\n",
    "    (0, 1),\n",
    "#     (0, 9),\n",
    "#     (0, 9),\n",
    "#     (0, 9),\n",
    "#     (0, 9),\n",
    "#     (0, 9),\n",
    "#     (0, 9),\n",
    "#     (1, 9),\n",
    "#     (1, 9),\n",
    "#     (1, 9),\n",
    "#     (1, 9),\n",
    "#     (1, 9),\n",
    "#     (1, 9),\n",
    "#     (1, 9),\n",
    "#     (1, 9),\n",
    "#     (2, 9),\n",
    "#     (2, 9),\n",
    "#     (2, 9),\n",
    "#     (2, 9),\n",
    "#     (2, 9),\n",
    "#     (2, 9),\n",
    "#     (2, 9),\n",
    "#     (3, 9),\n",
    "#     (3, 9),\n",
    "#     (3, 9),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Environment(sharp_turn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = MCPlayer(EPSILON, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52min 19s, sys: 9.57 s, total: 52min 29s\n",
      "Wall time: 52min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p.learn(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOOOOOOO\n",
      "OOOOOOO \n",
      "X       \n"
     ]
    }
   ],
   "source": [
    "p.play_and_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
